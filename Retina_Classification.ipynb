{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from skopt import BayesSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory path for the training set \n",
    "directory_path = '/Users/karansagar/Downloads/archive/Training_Set/Training_Set/Training'\n",
    "\n",
    "# List all files in the directory\n",
    "file_names = [file for file in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, file))]\n",
    "\n",
    "# sort the order of the list by the numerical part \n",
    "file_names.sort(key=lambda x: int(x.split('.')[0]))\n",
    "\n",
    "print(file_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images of the Retina provided in the dataset are quite large and computationally heavy. As a result, I've reszied the images to 256 x 256. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(output_folder, size):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    for file in file_names:\n",
    "        path = '/Users/karansagar/Downloads/archive/Training_Set/Training_Set/Training/' + file\n",
    "        img = Image.open(path)\n",
    "        img_resized = img.resize(size)\n",
    "            \n",
    "        output_path = os.path.join(output_folder, file)\n",
    "        img_resized.save(output_path)\n",
    "        #print(f\"Resized and saved: {output_path}\")\n",
    "\n",
    "\n",
    "output_folder = '/Users/karansagar/Desktop/Retina_Training'\n",
    "size = (256, 256)  # Desired size (width, height)\n",
    "resize_images(output_folder, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [] # empty list which will contain the pixels for all the flattened images \n",
    "\n",
    "for file in file_names:\n",
    "    path = '/Users/karansagar/Desktop/Retina_Classification/Retina_Training/' + file # path for the file\n",
    "    image = Image.open(path) \n",
    "    image = np.asarray(image) # covert image to a numpy array\n",
    "    flattened_image = image.flatten() # flatten the array\n",
    "    data.append(flattened_image) # append the array to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/karansagar/Desktop/Retina_Classification/RFMiD_Training_Labels.csv') # load the csv which contains the classifications (0 or 1)\n",
    "\n",
    "y = df['Disease_Risk'] # response data\n",
    "\n",
    "y = np.vstack(y) # changing the shape of the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values, counts = np.unique(y, return_counts=True)\n",
    "\n",
    "print(dict(zip(unique_values, counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the cell above, we see that our classes are not balanced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test) \n",
    "\n",
    "y_train = y_train.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I'm using Bayesian Optimization to find the optimal hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the pipeline\n",
    "clf = Pipeline([\n",
    "    (\"pca\", PCA()),\n",
    "    (\"rnd\", RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Define the param_grid with integer values for n_components and others\n",
    "param_grid = {\n",
    "    \"pca__n_components\": np.arange(50, 1228 - 50, 50),  # Integer range for PCA components \n",
    "    \"rnd__n_estimators\": np.arange(10, 500, 25),  # Integer range for values for n_estimators\n",
    "    \"rnd__max_depth\": np.arange(10, 500, 25),  # Integer range for max_depth\n",
    "    \"rnd__max_leaf_nodes\": np.arange(10, 500, 25),  # Integer values for max_leaf_nodes\n",
    "}\n",
    "\n",
    "# Perform Bayesian optimization\n",
    "opt = BayesSearchCV(clf, param_grid, n_iter=32, cv=cv_folds, scoring='roc_auc')\n",
    "opt.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters found: \", opt.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=50)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train_scaled) # Apply PCA transformation to train test\n",
    "X_test_pca = pca.transform(X_test_scaled) # Apply PCA trnsformation to test test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators = 260, max_depth = 185, max_leaf_nodes = 35, random_state = 42) # Initialize Random Forest classifier \n",
    "rnd_clf.fit(X_train_pca, y_train) # fit the Random Forest Classfier to the training set \n",
    "\n",
    "y_pred_rnd = rnd_clf.predict(X_test_pca) # get the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a confusion matrix display\n",
    "cm_rnd = confusion_matrix(y_test, y_pred_rnd, labels=rnd_clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_rnd, display_labels=rnd_clf.classes_)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "plt.title('Confusion Matrix for Random Forest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf = SGDClassifier(loss= 'log_loss') # Initialize Stochastic Gradient Descent Classifier \n",
    "sgd_clf.fit(X_train_pca, y_train) # fit the Stochastic Gradient Descent Classfier to the training set \n",
    "\n",
    "y_pred_sgd = sgd_clf.predict(X_test_pca) # get the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a confusion matrix display\n",
    "cm_sgd = confusion_matrix(y_test, y_pred_sgd, labels=sgd_clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_sgd, display_labels=sgd_clf.classes_)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "plt.title('Confusion Matrix for Stochastic Gradient Descent')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline\n",
    "clf = Pipeline([\n",
    "    (\"pca\", PCA()),\n",
    "    (\"svc\", SVC())\n",
    "])\n",
    "\n",
    "# Define the param_grid with integer values for n_components, gamma, C for Support Vector Classifier \n",
    "param_grid = {\n",
    "    \"pca__n_components\": np.arange(50, 1228 - 50, 50),  # Integer range for PCA components \n",
    "    \"svc__gamma\": np.linspace(0, 5, 250),  # Integer range for values for gamma\n",
    "    \"svc__C\": np.linspace(0, 500, 500),  # Integer range for C\n",
    "}\n",
    "\n",
    "# Perform Bayesian optimization\n",
    "opt = BayesSearchCV(clf, param_grid, n_iter=32, cv=cv_folds, scoring='roc_auc')\n",
    "opt.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters found: \", opt.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_clf = SVC(kernel='rbf', gamma= 0.001, C=1.0) # Intialize the Support Vector Classifier using the specified Kernel, gamma, and C parameters \n",
    "svc_clf.fit(X_train, y_train) # fit the Support Vector classfier to the training set \n",
    "\n",
    "y_pred_svc = svc_clf.predict(X_test) # get the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a confusion matrix display\n",
    "cm_svc = confusion_matrix(y_test, y_pred_svc, labels=svc_clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_svc, display_labels=svc_clf.classes_)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "plt.title('Confusion Matrix for Support Vector Machines')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
